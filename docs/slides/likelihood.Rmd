---
title: |
    | Bayesian statistics with R
    | 2. The likelihood
author: "Olivier Gimenez"
date: "March 2021"
output:
  beamer_presentation:
    fig_caption: no
    includes:
      in_header: header.tex
    latex_engine: pdflatex
    slide_level: 2
    theme: metropolis
  ioslides_presentation: default
classoption: aspectratio=169
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = FALSE, 
                      echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      fig.height=6, 
                      fig.width = 1.777777*6,
                      tidy = FALSE, 
                      comment = NA, 
                      highlight = TRUE, 
                      prompt = FALSE, 
                      crop = TRUE,
                      comment = "#>",
                      collapse = TRUE)
knitr::opts_knit$set(width = 60)
library(tidyverse)
library(reshape2)
theme_set(theme_light(base_size = 16))
make_latex_decorator <- function(output, otherwise) {
  function() {
      if (knitr:::is_latex_output()) output else otherwise
  }
}
insert_pause <- make_latex_decorator(". . .", "\n")
insert_slide_break <- make_latex_decorator("----", "\n")
insert_inc_bullet <- make_latex_decorator("> *", "*")
insert_html_math <- make_latex_decorator("", "$$")
```



# Likelihood

## Context

`r insert_inc_bullet()` Usually, when talking about probability distributions, we assume that we know the parameter values.

`r insert_inc_bullet()` In the real world, it is usually the other way around.

## A question of interest might be for example: 

> We have observed 3 births by a female during her 10 breeding
attempts. What does this tell us about the true probability of
getting a successful breeding attempt from this female? For the population?

`r insert_slide_break()`

* We don’t know what the probability of a birth is.

* But we can calculate the probability of getting our data for different values:

```{r,collapse=TRUE}
dbinom(x=3,size=10,prob=0.1)
```

`r insert_slide_break()`

* We don’t know what the probability of a birth is. 

* But we can see what the probability of getting our data would be for different values:

```{r,collapse=TRUE}
dbinom(x=3,size=10,prob=0.9)
```

`r insert_slide_break()`

* We don’t know what the probability of a birth is. 

* But we can see what the probability of getting our data would be for different values:

```{r,collapse=TRUE}
dbinom(x=3,size=10,prob=0.25)
```

`r insert_slide_break()`

```{r,collapse=TRUE}
dbinom(x=3,size=10,prob=0.1)
dbinom(x=3,size=10,prob=0.9)
dbinom(x=3,size=10,prob=0.25)
```

So we would be more likely to observe 3 births if the probability is 0.25 than 0.1 or 0.9.

## The likelihood

* This reasoning is so common in statistics that it has a special name:

`r insert_pause()`

* **The likelihood** is the probability of observing the data under a certain model.

`r insert_pause()`

* The data are known, we usually consider the likelihood as a function of the model parameters $\theta_1,\theta_2, \ldots, \theta_p$

$$L = P(\theta_1,\theta_2, \ldots, \theta_p \mid \text{data})$$

## Likelihood functions

We may create a function to calculate a likelihood:

```{r,collapse=TRUE}
lik.fun <- function(parameter){
  ll <- dbinom(x=3, size=10, prob=parameter)
  return(ll)
}

lik.fun(0.3)

lik.fun(0.6)
```

## Maximize the likelihood (3 successes ot of 10 attempts)

```{r, echo=FALSE}
lik.fun <- function(parameter){
  ll <- dbinom(x=3, size=10, prob=parameter)
  return(ll)
}
p.grid = seq(0,1,by=0.01)
lik = rep(NA,length(p.grid))
for (i in 1:length(p.grid)){
  lik[i] <- lik.fun(p.grid[i])
}
plot(p.grid,lik,xlab='Probability of getting a successful breeding',ylab='Likelihood',type='l',lwd=3,cex.lab=1.5)
abline(v=0.3,lty=2,lwd=2,col='blue')
```

The *maximum* of the likelihood is at value $0.3$

## Maximum likelihood estimation

* There is always a set of parameters that gives you the highest likelihood of observing the data, and this is the MLE.

`r insert_pause()`

* These can be calculated using:

     + Trial and error (not efficient!).
     + Compute the maximum of a function by hand (rarely doable in practice).
     + An iterative optimization algorithm: `?optim` in `R`.
     
## By hand: compute MLE of $p$ from $Y \sim \text{Bin}(N=10,p)$ with $k=3$ successes

`r insert_inc_bullet()` $P(Y=k) = {{k}\choose{N}} p^k (1-p)^{N-k} = L(p)$.

`r insert_inc_bullet()` $\log(L(p)) = \text{cte} + k \log(p) + (N-k) \log(1-p)$.

`r insert_inc_bullet()` We are searching for the maximum of $L$, or equivalently that of $\log(L)$.

`r insert_inc_bullet()` Compute derivate w.r.t. $p$: $\displaystyle{{{d\log(L)}\over{dp}} = {{k}\over{p}} - {{(N-k)}\over{(1-p)}}}$.

`r insert_inc_bullet()` Then solve $\displaystyle{{{d\log(L)}\over{dp}}=0}$; the MLE is $\displaystyle{\hat{p} = {{k}\over{N}}={{3}\over{10}}=0.3}$.

`r insert_inc_bullet()` Here, the MLE is the proportion of observed successes.

## Using a computer: MLE of $p$ from $Y \sim \text{Bin}(N=10,p)$ with $k=3$ successes

```{r,collapse=TRUE}
lik.fun <- function(parameter) dbinom(x=3, size=10, prob=parameter)
# ?optimize
optimize(lik.fun,c(0,1),maximum=TRUE)
```

Use `optim` when the number of parameters is $> 1$.

## Using a computer: MLE of $p$ from $Y \sim \text{Bin}(N=10,p)$ with $k=3$ successes

```{r, echo=FALSE}
lik.fun <- function(parameter) dbinom(x=3, size=10, prob=parameter)
plot(lik.fun,0,1,xlab="probability of success (p)",ylab="log-likelihood(p)",main="Binomial likelihood with 3 successes ot of 10 attempts",lwd=3,cex.lab=1.5, cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
abline(v=0.3,h=0.26682,col='blue',lty=2,lwd=2)
```

# Your turn

## MLE of the parameters of a Normal distribution

* Assume we have collected data on the height of 100 people:
```{r}
# set seed for random numbers
set.seed(2020)
# simulate data from Normal distribution
n <- 100
height <- rnorm(n, mean=170, sd=10)
```

`r insert_slide_break()`

```{r echo=FALSE}
data.frame(height=height) %>%
  ggplot(aes(x=height))+ 
  geom_histogram(color="blue",fill="dodgerblue") + 
  labs(x = "Height", y = 'Density')
```

`r insert_slide_break()`

* We consider a Normal distribution for the model. 

* Compute the MLE of the parameters of the Normal distribution.

* Hint: Use functions `optim()` and `dnorm()`

# Solution

## `R` code 

* Write a function for the likelihood of a Normal distribution with parameters mean $\mu$ and standard deviation $\sigma$:
```{r}
negloglik <- function(theta, data) {
  mu <- theta[1]
  sigma <- theta[2]
  x <- data
  -sum(dnorm(x, mean = mu, sd = sigma, log = TRUE))
}
negloglik(theta = c(150,1), height)
```

`r insert_slide_break()`

* Minimiiiiiize
```{r}
fit <- optim(par = c(1,1), fn = negloglik, data = height)
fit
```

`r insert_slide_break()`

```{r, echo = FALSE}
binwidth <- 1 
df <- data.frame(x = height) %>%
  ggplot(aes(x = height, mean = fit$par[1], sd = fit$par[2], binwidth = binwidth, n = n)) +
  geom_histogram(binwidth = binwidth, 
                 colour = "white", 
                 fill = "cornflowerblue", 
                 size = 0.1) +
  stat_function(fun = function(x) dnorm(x, mean = fit$par[1], sd = fit$par[2]) * n * binwidth,
    color = "darkred", size = 1)
df
```


