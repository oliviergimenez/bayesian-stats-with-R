---
title: |
    | Bayesian statistics with R
    | 8. Heterogeneity and multilevel models (aka mixed models)
author: "Olivier Gimenez"
date: "November-December 2024"
output:
  beamer_presentation:
    fig_caption: no
    includes:
      in_header: header.tex
    latex_engine: pdflatex
    slide_level: 2
    theme: metropolis
  ioslides_presentation: default
classoption: aspectratio=169
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = FALSE, 
                      echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      fig.height=6, 
                      fig.width = 1.777777*6,
                      tidy = FALSE, 
                      comment = NA, 
                      highlight = TRUE, 
                      prompt = FALSE, 
                      crop = TRUE,
                      comment = "#>",
                      collapse = TRUE)
knitr::opts_knit$set(width = 60)
library(tidyverse)
library(reshape2)
library(R2jags)
theme_set(theme_light(base_size = 16))
make_latex_decorator <- function(output, otherwise) {
  function() {
      if (knitr:::is_latex_output()) output else otherwise
  }
}
insert_pause <- make_latex_decorator(". . .", "\n")
insert_slide_break <- make_latex_decorator("----", "\n")
insert_inc_bullet <- make_latex_decorator("> *", "*")
insert_html_math <- make_latex_decorator("", "$$")
```


# Multilevel (aka mixed-effect) models

## What are multilevel models?

`r insert_inc_bullet()` Multilevel models include both fixed and random effects.

`r insert_inc_bullet()` Random effects are statistical parameters that attempt to **explain noise caused by clusters** of the population you are trying to model.

`r insert_inc_bullet()` A multilevel model assumes that the dataset being analysed consists of **a hierarchy of different populations** whose differences relate to that hierarchy.

`r insert_inc_bullet()` Measurement that come **in clusters** or groups.

`r insert_inc_bullet()` Come up with examples of clusters or groups.

## Clusters might be:

* Classrooms within schools
* Students within classrooms
* Chapters within books
* Individuals within populations
* Populations within species
* Trajectories within individuals
* Fishes within tanks
* Frogs within ponds
* PhD applicants in doctoral schools
* Nations in continents
* Sex or age are not clusters per se (if we were to sample again, we would take the same levels, e.g. male/female and young/old)


## Why do we need multilevel models?

`r insert_inc_bullet()` Model the clustering itself.

`r insert_inc_bullet()` Interested in variance components (environmental vs. genetic variance).

`r insert_inc_bullet()` Control for bias due to pseudoreplication (time, space, individual).

## McElreath's explanation of multilevel models

`r insert_inc_bullet()` Fixed-effect models have amnesia.

`r insert_inc_bullet()` Every new cluster (individual, species, classroom) is a new world.

`r insert_inc_bullet()` No information passed among clusters.

`r insert_inc_bullet()` Multilevel models remember and pool information. They have memory.

`r insert_inc_bullet()` Properties of clusters come from a population.

`r insert_inc_bullet()` If previous clusters improve your guess about a new cluster, you want to use pooling.


## Plant experiment in the field at CEFE 

```{r, out.width = '8cm',out.height='6cm',fig.align='center',echo=FALSE}
knitr::include_graphics(here::here("slides","img","pdm.png"))
```

Courtesy of Pr Eleni Kazakou

## Number of grains per species (cluster) as a function of biomass
```{r, include=FALSE}
# On lit le jeu de données à analyser et on le nettoie
VMG <- read_csv2(here::here("slides","dat","VMG.csv")) %>%
  mutate(Sp = as_factor(Sp),
         Vm = as.numeric(Vm))

# crée crée un vecteur contenant le nb de graines (en log)
y <- VMG$NGrTotest

# crée un vecteur contenant la biomass
x <- VMG$Vm

# crée un vecteur contenant le nom des espèces
Sp <- VMG$Sp

# crée un vecteur contenant le numéro des espèces
species <- as.numeric(Sp)

# nombre d'espèces
nbspecies <- length(levels(Sp)) # ou bien length(unique(species))

# nombre de mesures
n <- length(y)
```
```{r, echo=FALSE, fig.align = 'center', out.width = '12cm', out.height='7cm'}
# graphical representation
library(lattice)
dat <- data.frame(Biomass=x,nb_grain=y,Species=Sp)
xyplot(log(nb_grain) ~ Biomass | Species,data=dat,
       xlab='Biomass',ylab='Number of grains (log transformed)')
```


## GLM with complete pooling

`r insert_html_math()`
\begin{align*}
   \text{Y}_i &\sim \text{Distribution(mean}_i\text{)} &\text{[likelihood]} \\
  \text{link(mean)}_i & = \alpha + \beta \; x_{i} &\text{[linear model]} \\
  \alpha &\sim \text{to be determined} &\text{[prior for intercept}] \\ 
  \beta &\sim \text{to be determined} &\text{[prior for slope}] \\ 
\end{align*}
`r insert_html_math()`

**Model with complete pooling. All clusters the same.**

## GLM with no pooling

`r insert_html_math()`
\begin{align*}
   \text{Y}_i &\sim \text{Distribution(mean}_i\text{)} &\text{[likelihood]} \\
  \text{link(mean)}_i & = \alpha_{\text{CLUSTER}[i]} + \beta \; x_{i} &\text{[linear model]} \\
  \alpha_j &\sim \text{to be determined} &\text{[prior for intercept}] \\ 
  \beta &\sim \text{to be determined} &\text{[prior for slope}] \\ 
\end{align*}
`r insert_html_math()`

**Model with no pooling. All clusters unrelated (fixed effect).**

## GL**M**M or GLM with partial pooling

`r insert_html_math()`
\begin{align*}
   \text{Y}_i &\sim \text{Distribution(mean}_i\text{)} &\text{[likelihood]} \\
  \text{link(mean)}_i & = \alpha_{\text{CLUSTER}[i]} + \beta \; x_{i} &\text{[linear model]} \\
  \alpha_j &\sim \text{Normal}(\bar{\alpha}, \sigma) &\text{[prior for varying intercepts}] \\ 
  \bar{\alpha} &\sim \text{to be determined} &\text{[prior for population mean}] \\
  \sigma &\sim \text{to be determined} &\text{[prior for standard deviation}] \\ 
  \beta &\sim \text{to be determined} &\text{[prior for slope}] \\ 
\end{align*}
`r insert_html_math()`

**Model with partial pooling. Clusters are somehow related (random effect).**

# Back to the plant example

## Model with complete pooling (all species are the same)

`r insert_html_math()`
\begin{align*}
   \text{nseeds}_i &\sim \text{Normal}(\mu_i,\sigma^2) &\text{[likelihood]} \\
  \mu_i & = \alpha + \beta \; \text{biomass}_{i} &\text{[linear model]} \\
  \alpha &\sim \text{Normal}(0,1000) &\text{[prior for intercept}] \\ 
  \beta &\sim \text{Normal}(0,1000) &\text{[prior for slope}] \\
  \sigma &\sim \text{Uniform}(0,100) &\text{[prior for standard deviation}] \\
\end{align*}
`r insert_html_math()`

## Read in and manipulate data

\footnotesize

```{r}
# read in data
VMG <- read_csv2(here::here("slides","dat","VMG.csv")) %>%
  mutate(Sp = as_factor(Sp), Vm = as.numeric(Vm))
# nb of seeds
y <- log(VMG$NGrTotest)
# biomass
x <- VMG$Vm
x <- (x - mean(x))/sd(x)
# species name
Sp <- VMG$Sp
# species label
species <- as.numeric(Sp)
# species name
nbspecies <- length(levels(Sp))
# total nb of measurements 
n <- length(y)
```

\normalsize

## Specify the model in Jags

\footnotesize

```{r}
model <- 
paste("
model{
for(i in 1:n){
	y[i] ~ dnorm(mu[i], tau.y)
	mu[i] <- a + b * x[i]
	}
tau.y <- 1 / (sigma.y * sigma.y)
sigma.y ~ dunif(0,100)
a ~ dnorm(0,0.001)
b ~ dnorm(0,0.001)
}
")
writeLines(model,here::here("slides","code","completepooling.bug"))
```

\normalsize

## Prepare ingredients for running Jags

```{r}
# data
allom.data <- list(y = y, n = n, x = x)

# initial values
init1 <- list(a=rnorm(1), b=rnorm(1),sigma.y=runif(1))
init2 <- list(a=rnorm(1), b=rnorm(1),sigma.y=runif(1))
inits <- list(init1,init2)

# parameters to be estimated
allom.parameters <- c("a", "b", "sigma.y")
```

## Run Jags

\footnotesize

```{r}
allom.1 <- jags(allom.data,
                inits,
                allom.parameters,
                n.iter = 2500,
                model.file = here::here("slides","code","completepooling.bug"), 
                n.chains = 2, 
                n.burn = 1000)
```

\normalsize

## Display results

\footnotesize

```{r}
allom.1
```

\normalsize

## Compare with Frequentist approach

```{r}
freq_lm <- lm(y ~ x, data = allom.data)	
freq_lm
```

## Output

```{r echo=FALSE}
library(lattice)
xyplot(y ~ x | Sp,
       xlab = "Biomass", ylab = "Number of seeds", main="complete pooling",
       panel = function(x, y) {
           panel.xyplot(x, y)
           panel.abline(a = c(13.93, 3.57),col='red',lwd=3)
       })
```

## Model with partial pooling (species random effect)

```{r, fig.align = 'center' , echo = FALSE, out.width = '12cm'}
knitr::include_graphics(here::here("slides","img","varyingint.png"))
```

## Model with partial pooling (all species related in some way)

`r insert_html_math()`
\begin{align*}
   \text{nseeds}_i &\sim \text{Normal}(\mu_i,\sigma^2) &\text{[likelihood]} \\
  \mu_i & = \alpha_{\text{species}[i]} + \beta \; \text{biomass}_{i} &\text{[linear model]} \\
  \alpha_j &\sim \text{Normal}(\bar{\alpha},\sigma_{\alpha}) &\text{[prior for varying intercepts}] \\ 
  \bar{\alpha} &\sim \text{Normal}(0,1000) &\text{[prior for population mean}] \\ 
  \sigma_{\alpha} &\sim \text{Uniform}(0,100) &\text{[prior for }\sigma_{\alpha}] \\
  \beta &\sim \text{Normal}(0,1000) &\text{[prior for slope}] \\ 
  \sigma &\sim \text{Uniform}(0,100) &\text{[prior for }\sigma] \\
\end{align*}
`r insert_html_math()`

## Implementation in Jags

\footnotesize

```{r}
model <- paste("
model {
  for (i in 1:n){
    y[i] ~ dnorm(mu[i], tau.y)
    mu[i] <- a[species[i]] + b * x[i]
  }
  tau.y <- 1/ (sigma.y * sigma.y)
  sigma.y ~ dunif(0, 100)
  for (j in 1:nbspecies){ 
    a[j] ~ dnorm(mu.a, tau.a)
  }
  mu.a ~ dnorm(0, 0.001)
  tau.a <- 1/(sigma.a * sigma.a)
  sigma.a ~ dunif(0, 100)
  b ~ dnorm (0, 0.001)    
}")
writeLines(model,here::here("slides","code","varint.bug"))
```

\normalsize

## Prepare ingredients for running Jags

```{r}
allom.data <- list(n = n, 
                   nbspecies = nbspecies,
                   x = x,
                   y = y,
                   species = species)
init1 <- list(a = rnorm(nbspecies), b = rnorm(1), mu.a = rnorm(1), 
              sigma.y = runif(1), sigma.a=runif(1))
init2 <- list(a = rnorm(nbspecies), b = rnorm(1), mu.a = rnorm(1), 
              sigma.y = runif(1), sigma.a = runif(1))
inits <- list(init1,init2)
allom.parameters <- c("b", "mu.a","sigma.y", "sigma.a")
```

## Run Jags

\footnotesize

```{r}
allom.2 <- jags(allom.data,
                inits,
                allom.parameters, 
                n.iter = 2500,
                model.file = here::here("slides","code","varint.bug"), 
                n.chains = 2, 
                n.burn = 1000)
```

\normalsize

## Display results

\footnotesize

```{r}
allom.2
```

\normalsize

## Compare with Frequentist approach

\footnotesize

```{r}
library(lme4)
freq_lmm <- lmer(y ~ x + (1 | species), allom.data, REML = FALSE)	
freq_lmm
```

\normalsize

```{r include = FALSE}
allom.2 <- jags(allom.data,
                inits,
                parameters.to.save = c("a", "b", "mu.a","sigma.y", "sigma.a"), 
                n.iter = 2500,
                model.file = here::here("slides","code","varint.bug"), 
                n.chains = 2, 
                n.burn = 1000)

## graph
acoef.sp <- allom.2$BUGSoutput$summary[1:33,1]
bcoef <- allom.2$BUGSoutput$summary[34,1]

# varying-intercept predicted values
yfit <- rep(0,length=n)
for (k in 1:n){yfit[k] <- acoef.sp[species[k]] + bcoef * x[k]}

# pooling model (no species effect) predicted values
ylinear <- rep(0,length=n)
for (k in 1:n){ylinear[k] <- 13.92 + 3.57 * x[k]}

## define function to fit observed and predicted values in species-specific panels 
panelfun2 <- 
  function(x, y, subscripts, ...){ 
           llines(x, lmhat[subscripts], type="p") # observed data
           llines(x, hat[subscripts], type="l", lty=1,col='green',lwd=3) # partial pooling
           llines(x, hat2[subscripts], type="l", lty=1,col='red',lwd=3) # no pooling 
} 

# assign observed and predicted values
lmhat <- y # observed data
hat <- yfit # partial pooling
hat2 <- ylinear # no pooling
```

## Compare \textcolor{red}{complete pooling} vs \textcolor{green}{partial pooling}

```{r echo=FALSE}
# build a multipanel plot 
xyplot(y ~ x | Sp, panel=panelfun2,
       xlab="Biomass", 
       ylab="Number of seeds",      
       key = list(text = list(c("partial pooling", "complete pooling")),
       lines = list(lwd = 3, col = c("green", "red"),
       type = c("l", "l"))))
```

## Model with no pooling (all species unrelated)

`r insert_html_math()`
\begin{align*}
   \text{nseeds}_i &\sim \text{Normal}(\mu_i,\sigma^2) &\text{[likelihood]} \\
  \mu_i & = \alpha_{\text{species}[i]} + \beta \; \text{biomass}_{i} &\text{[linear model]} \\
  \alpha_j &\sim \text{Normal}(0,1000) &\text{[prior for intercepts}] \\ 
  \beta &\sim \text{Normal}(0,1000) &\text{[prior for slope}] \\ 
  \sigma &\sim \text{Uniform}(0,100) &\text{[prior for}\sigma] \\
\end{align*}
`r insert_html_math()`

## Implementation in Jags

\footnotesize

```{r}
model <- paste("
model {
  for (i in 1:n){
    y[i] ~ dnorm (mu[i], tau.y)
    mu[i] <- a[species[i]] + b * x[i]
  }
  tau.y <- 1 / (sigma.y * sigma.y)
  sigma.y ~ dunif(0, 100)
  for (j in 1:nbspecies){
    a[j] ~ dnorm(0, 0.001)
  }
  b ~ dnorm(0,0.1)    
}")
writeLines(model,here::here("slides","code","nopooling.bug"))
```

\normalsize

## Prepare ingredients

```{r include = TRUE}
allom.data <- list(n = n, 
                   nbspecies = nbspecies, 
                   x = x, 
                   y = y, 
                   species = species)
init1 <- list(a = rnorm(nbspecies), b = rnorm(1), sigma.y = runif(1))
init2 <- list(a = rnorm(nbspecies), b = rnorm(1), sigma.y = runif(1))
inits<-list(init1, init2)
allom.parameters <- c("a","b","sigma.y")
```

```{r include = FALSE}
# on specifie le modele 
model <- 
paste("
model {
  for (i in 1:n){
    y[i] ~ dnorm (mu[i], tau.y)
    mu[i] <- a[species[i]] + b *x[i]
  }

  tau.y <- pow(sigma.y, -2)
  sigma.y ~ dunif(0, 100)

  for (j in 1:nbspecies){
    a[j] ~ dnorm (0, 0.001)
  }
  
  b ~ dnorm (0, 0.1)

}
")
writeLines(model,here::here("slides","code","nopooling.bug"))
```

## Run JAGS

\footnotesize

```{r include = TRUE}
allom.3 <- jags(data = allom.data,
                inits = inits,
                parameters.to.save = allom.parameters, 
                n.iter = 2500,
                model.file = here::here("slides","code","nopooling.bug"), 
                n.chains = 2, 
                n.burn = 1000)
```

\normalsize

## Display results

\footnotesize

```{r}
allom.3$BUGSoutput$summary[c(1:4, 32:33, 34), -c(4,6)]
```

\normalsize

## Compare with Frequentist approach

```{r}
lm(y ~ -1 + as.factor(species) + x, data = allom.data) %>% 
  broom::tidy() %>% 
  slice(c(1:4, 32:33, 34))
```


```{r include = FALSE}
## graph (correction BUG 2015)
acoef.sp <- allom.3$BUGSoutput$summary[1:33,1]
bcoef <- allom.3$BUGSoutput$summary[34,1]

# fixed-effect predicted values
yfit2 <- rep(0,length=n)
for (k in 1:n){yfit2[k] <- acoef.sp[species[k]] + bcoef * x[k]}

```

## Compare \textcolor{red}{complete pooling} vs \textcolor{green}{partial pooling} vs \textcolor{blue}{no pooling}

```{r echo=FALSE}
## define function to fit observed and predicted values in species-specific panels 
panelfun3 <- 
  function(x, y, subscripts, ...){ 
           llines(x, lmhat[subscripts], type = "p") # observed data
           llines(x, hat[subscripts], type="l", lty=1,col='green',lwd=3) # partial pooling
           llines(x, hat2[subscripts], type="l", lty=1,col='red',lwd=3) # no pooling
          llines(x, hat3[subscripts]+0.5, type="l", lty=1,col='blue',lwd=3) # complete pooling
}

# assign observed and predicted values
lmhat <- y # observed data
hat <- yfit # partial pooling
hat2 <- ylinear # no pooling
hat3 <- yfit2 # complete pooling

# build a multipanel plot 
xyplot(y ~ x | Sp, panel = panelfun3,  
       xlab="Biomass", 
       ylab="Number of seeds",      
       key = list(text = list(c("partial pooling", "complete pooling", "no pooling")),
       lines = list(lwd = 3, col = c("green", "red", "blue"),
       type = c("l", "l", "l"))))
```


# Bonus: Model with varying intercept and varying slope

## Code: part 1

```{r echo=FALSE}
model <- 	
paste("	
# varying-intercept, varying-slope allometry model 	
# with Vm as a species predictor 	
	
model {	
  for (i in 1:n){	
    y[i] ~ dnorm (mu[i], tau.y)	
    mu[i] <- a[species[i]] + b[species[i]] * x[i]	
  }	
	
  tau.y <- pow(sigma.y, -2)	
  sigma.y ~ dunif (0, 100)	
	
  for (j in 1:nbspecies){	
    a[j] ~ dnorm (mu.a, tau.a)	
    b[j] ~ dnorm (mu.b, tau.b)	
  }	
  	
  mu.a ~ dnorm (0, .001)	
  tau.a <- pow(sigma.a, -2)	
  sigma.a ~ dunif (0, 100)	
	
  mu.b ~ dnorm (0, .001)	
  tau.b <- pow(sigma.b, -2)	
  sigma.b ~ dunif (0, 100)	
	
}	
")	
writeLines(model,here::here("slides","code","varintvarslope.bug"))
```


```{r eval = FALSE}
model <- 	
paste("	
# varying-intercept, varying-slope allometry model 	
# with Vm as a species predictor 	
	
model {	
  for (i in 1:n){	
    y[i] ~ dnorm (mu[i], tau.y)	
    mu[i] <- a[species[i]] + b[species[i]] * x[i]	
  }	
	
  tau.y <- pow(sigma.y, -2)	
  sigma.y ~ dunif (0, 100)	
	
...
```

## Code: part 2

```{r eval = FALSE}
  for (j in 1:nbspecies){	
    a[j] ~ dnorm (mu.a, tau.a)	
    b[j] ~ dnorm (mu.b, tau.b)	
  }	
  	
  mu.a ~ dnorm (0, .001)	
  tau.a <- pow(sigma.a, -2)	
  sigma.a ~ dunif (0, 100)	
  mu.b ~ dnorm (0, .001)	
  tau.b <- pow(sigma.b, -2)	
  sigma.b ~ dunif (0, 100)	
	
}	
")	
writeLines(model,here::here("slides","code","varintvarslope.bug"))
```


## Prepare ingredients

```{r}
init1 <- list(a = rnorm(nbspecies), b = rnorm(nbspecies), 
              mu.a = rnorm(1), mu.b = rnorm(1),	
              sigma.y = runif(1), sigma.a = runif(1), sigma.b = runif(1))	
init2 <- list(a = rnorm(nbspecies), b = rnorm(nbspecies), 
              mu.a = rnorm(1), mu.b = rnorm(1),	
              sigma.y = runif(1), sigma.a = runif(1), sigma.b = runif(1))	
inits <- list(init1, init2)	
allom.parameters <- c ("a","b","mu.a","mu.b","sigma.y","sigma.a","sigma.b")
```

## Run Jags

\footnotesize

```{r}
allom.4 <- jags(data = allom.data,
                inits = inits,
                parameters.to.save = allom.parameters, 
                n.iter = 2500,
                model.file = here::here("slides","code","varintvarslope.bug"), 
                n.chains = 2, 
                n.burn = 1000)	
```

\normalsize

## Display results

\footnotesize

```{r}
round(allom.4$BUGSoutput$summary[c(1:2, 32:33, 34:35, 65:66, 68:72), -c(4,6)],2)
```

\normalsize

## Compare with Frequentist approach

\footnotesize

```{r}
freq_lmm2 <- lmer (y ~ x + (1 + x | species), allom.data, REML = FALSE)	
freq_lmm2
```

\normalsize

## Compare with Frequentist approach - with no correlation

\footnotesize

```{r}
freq_lmm_wocorr <- lmer(y ~ x + (1 | species) + 	
                                   (0 + x | species), allom.data, REML = FALSE)	
freq_lmm_wocorr
```

\normalsize

## Shrinkage results from pooling of information

`r insert_inc_bullet()` Varying effect estimates shrink towards mean ($\bar{\alpha}$).

`r insert_inc_bullet()` Avoids underfitting as in complete pooling model (null variance) or overfitting as in no pooling model (infinite variance).

`r insert_inc_bullet()` Varying effects: adaptive regularization through cluster variance estimation.

`r insert_inc_bullet()` Further from mean, more shrinkage.

`r insert_inc_bullet()` Fewer data in cluster, more shrinkage.

# Multilevel models are awesome!

## Multilevel models in a nutshell

`r insert_inc_bullet()` **Shrinkage via pooling is desirable**. The no-pooling model overstates variation among clusters and makes the
individual clusters look more different than they are (overfitting). The complete-pooling model simply ignores the variation among clusters (underfitting).

`r insert_inc_bullet()` We can **generalize to a wider population**. Is there an allometry relationship between number of seeds and biomass?

`r insert_inc_bullet()` We may consider **varying slopes**. We'd need to deal with correlations between intercept and slope random effects. Open a whole new world with spatial (or time) autocorrelation, phylogenetic regressions, quantitative genetics, network models.

`r insert_inc_bullet()` We may **include predictors at the cluster level**. Imagine we know something about functional traits, and wish to determine whether some species-to-species variation in the allometry relationship is explained by these traits. 

# Your turn: Practical 8

# Conclusions

## Take-home messages about Bayesian statistics

* Frees the modeler in you (M. Kéry)
     + Uses probability to quantify uncertainty for everything (propagation of uncertainty).
     + Allows use of prior information ('better' estimates).
     + Can fit complex (hierarchical) models with same MCMC algorithms.

`r insert_pause()`

* With great tools come great responsabilities
  + Checking convergence is painful.
  + Specifying priors might be tricky.
  + Model adequacy should be checked (posterior predictive checks - not covered).
  + Computational burden can be high (see function `R2jags::jags.parallel()` and package [\alert{`jagsUI`}](https://github.com/kenkellner/jagsui).

`r insert_pause()`

* So what?
     + Make an informed and pragmatic choice.
     + Are you after complexity, speed, uncertainties, etc?
     + Talk to colleagues.

`r insert_slide_break()`

```{r, out.width = '13cm',out.height='5cm',fig.align='center',echo=FALSE}
knitr::include_graphics(here::here("slides","img","bayesian_evol.png"))
```

## [\alert{Why become a bayesian? Ask twitter!}](https://twitter.com/ChelseaParlett/status/1282798645453000704)

```{r, fig.align='center', echo=FALSE}
knitr::include_graphics(here::here("slides","img","whytwitter.png"))
```

# Your turn: Practical 9

